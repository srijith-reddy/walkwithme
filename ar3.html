<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<title>WalkWithMe – AR Level 3 (YOLO + GPT-4o Vision)</title>

<style>
body {
  margin: 0;
  overflow: hidden;
  background: black;
  font-family: -apple-system, Arial, sans-serif;
  color: white;
}

/* Camera feed */
#camera {
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
  z-index: 1;
}

/* Arrow */
#arrow {
  position: fixed;
  top: 45%;
  left: 50%;
  width: 140px;
  transform: translate(-50%, -50%);
  opacity: 0.95;
  z-index: 15;
}

/* Bounding boxes */
#boxes {
  position: fixed;
  top: 0; left: 0;
  width: 100vw;
  height: 100vh;
  z-index: 10;
  pointer-events: none;
}

/* AI Label */
#visionBox {
  position: fixed;
  bottom: 0;
  width: 100%;
  background: rgba(0,0,0,0.55);
  padding: 14px 16px;
  font-size: 18px;
  line-height: 1.3;
  font-weight: 500;
  z-index: 25;
  backdrop-filter: blur(4px);
  max-height: 32%;
  overflow-y: auto;
}

/* Manual Re-Analyze Button */
#analyzeBtn {
  position: fixed;
  top: 15px;
  right: 15px;
  z-index: 30;
  padding: 10px 16px;
  background: rgba(0,0,0,0.6);
  color: cyan;
  border: 1px solid cyan;
  border-radius: 10px;
  font-size: 15px;
}
</style>
</head>


<body>

<video id="camera" autoplay playsinline></video>
<canvas id="boxes"></canvas>

<img id="arrow" src="nav_arrow.png">

<div id="visionBox">Initializing…</div>
<button id="analyzeBtn">Analyze Scene</button>

<!-- ONNX Runtime -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>

<script>
/* ============================================================
   CAMERA SETUP
============================================================ */
const video = document.getElementById("camera");

navigator.mediaDevices.getUserMedia({
  video: { facingMode: "environment" },
  audio: false
}).then(stream => {
  video.srcObject = stream;
}).catch(err => {
  document.getElementById("visionBox").innerHTML = "Camera Permission Needed";
  console.error(err);
});


/* ============================================================
   LOAD YOLOv8n ONNX (ultra-fast)
============================================================ */
let yolo = null;

async function loadModel() {
  document.getElementById("visionBox").innerHTML = "Loading YOLO…";

  try {
    yolo = await ort.InferenceSession.create(
      "https://huggingface.co/onnx/models/resolve/main/yolov8n.onnx",
      { executionProviders: ["wasm"] }
    );

    document.getElementById("visionBox").innerHTML = "YOLO Ready";
  } catch (err) {
    console.error(err);
    document.getElementById("visionBox").innerHTML = "Failed to load YOLO";
  }
}
loadModel();


/* ============================================================
   PREP FRAME FOR YOLO
============================================================ */
function getFrameTensor() {
  const size = 320;
  const canvas = document.createElement("canvas");
  canvas.width = size;
  canvas.height = size;

  const ctx = canvas.getContext("2d");
  ctx.drawImage(video, 0, 0, size, size);

  const img = ctx.getImageData(0, 0, size, size);
  const data = new Float32Array(size * size * 3);

  for (let i = 0; i < size * size; i++) {
    data[i*3]   = img.data[i*4] / 255;
    data[i*3+1] = img.data[i*4+1] / 255;
    data[i*3+2] = img.data[i*4+2] / 255;
  }

  return new ort.Tensor("float32", data, [1, 3, size, size]);
}


/* ============================================================
   DANGER CLASSES
============================================================ */
const DANGER_CLASSES = new Set([
  0,  // person
  1,  // bicycle
  2,  // car
  3,  // motorcycle
  5,  // bus
  7,  // truck
  15, // dog
]);


/* ============================================================
   GPT-4o VISION COOLDOWN
============================================================ */
let lastVisionCall = 0;
const COOLDOWN = 25000; // 25 sec


/* ============================================================
   SEND TO BACKEND — FIXED PAYLOAD FIELD NAMES
============================================================ */
async function sendToVision(frameB64, objects) {

  // backend expects:
  // {
  //   image_b64: "...",
  //   detections: [...],
  //   heading: float,
  //   distance_to_next: null
  // }

  const payload = {
    image_b64: frameB64,
    detections: objects,
    heading: heading,
    distance_to_next: null
  };

  try {
    const res = await fetch("https://backend-floral-tree-4711.fly.dev/vision", {
      method: "POST",
      headers: {"Content-Type": "application/json"},
      body: JSON.stringify(payload)
    });

    const data = await res.json();
    if (data.ok) {
      document.getElementById("visionBox").innerHTML = data.analysis;
    } else {
      document.getElementById("visionBox").innerHTML = "Vision error";
    }
  } catch (err) {
    console.error(err);
    document.getElementById("visionBox").innerHTML = "Vision offline.";
  }
}


/* ============================================================
   MANUAL ANALYZE BUTTON
============================================================ */
document.getElementById("analyzeBtn").onclick = () => {
  lastVisionCall = 0;
};


/* ============================================================
   YOLO DETECTION LOOP
============================================================ */
async function detectLoop() {
  if (!yolo || video.readyState < 2) {
    requestAnimationFrame(detectLoop);
    return;
  }

  const tensor = getFrameTensor();
  const output = await yolo.run({ images: tensor });
  const raw = output[Object.keys(output)[0]].data;

  const ctx = document.getElementById("boxes").getContext("2d");
  ctx.canvas.width = window.innerWidth;
  ctx.canvas.height = window.innerHeight;
  ctx.clearRect(0,0,ctx.canvas.width,ctx.canvas.height);

  let dangerList = [];

  for (let i = 0; i < raw.length; i += 6) {
    const [x1, y1, x2, y2, score, cls] = raw.slice(i, i+6);
    if (score < 0.40) continue;

    if (DANGER_CLASSES.has(cls)) {
      dangerList.push({ cls, score, x1, y1, x2, y2 });
    }

    const sx = x1 / 320 * window.innerWidth;
    const sy = y1 / 320 * window.innerHeight;
    const sw = (x2 - x1) / 320 * window.innerWidth;
    const sh = (y2 - y1) / 320 * window.innerHeight;

    ctx.strokeStyle = DANGER_CLASSES.has(cls) ? "red" : "lime";
    ctx.lineWidth = 3;
    ctx.strokeRect(sx, sy, sw, sh);
  }

  if (dangerList.length && Date.now() - lastVisionCall > COOLDOWN) {
    lastVisionCall = Date.now();

    const snap = document.createElement("canvas");
    snap.width = 480;
    snap.height = 480;
    snap.getContext("2d").drawImage(video, 0, 0, 480, 480);

    const b64 = snap.toDataURL("image/jpeg", 0.65).split(",")[1];

    sendToVision(b64, dangerList);
  }

  requestAnimationFrame(detectLoop);
}
detectLoop();


/* ============================================================
   COMPASS / HEADING
============================================================ */
let heading = 0;

window.addEventListener("deviceorientation", (e) => {
  if (e.webkitCompassHeading !== undefined) {
    heading = e.webkitCompassHeading;
  } else if (e.alpha !== null) {
    heading = 360 - e.alpha;
  }
});

setInterval(() => {
  document.getElementById("arrow").style.transform =
    `translate(-50%, -50%) rotate(${-heading}deg)`;
}, 120);
</script>

</body>
</html>
